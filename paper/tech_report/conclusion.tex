\section{Conclusions and Future Work}\label{sec:conclusion}
We have shown how to improve transaction performance in an OCC system by integrating batching into the system architecture at the storage and the validator levels. Batching allows the reordering of requests and reduces the number of conflicts and aborts. We have formulated validator reordering as the problem of finding the minimal unweighted (or weighted) feedback vertex set in a directed graph, and we have proposed two greedy algorithms for finding a FVS that are flexible and that perform well in practice. We have carried out an extensive experimental study of storage and validator batching in a main memory transaction processing prototype. Our experiments show that there is a sweet spot for the optimal batch size, which is consistent with the intuition that the batch size should strike a balance between latency and the flexibility of reordering. We have also investigated the impact of storage and validator batching on system performance. While both kinds of batching improve the performance significantly, our experiments revealed that storage batching is always beneficial, while validator batching is most useful in moderate contention settings where its benefits outweigh the cost of running the reordering algorithm. We show two examples of more complex policies for validator reordering that aim to reduce tail latencies and help hard transactions. We finally show that intelligent batch creation by access patterns at the validator gives better abort rate and latency.

In summary, batching improves OCC performance significantly in all settings. In future work, we plan to explore more sophisticated batch creation techniques, as well as investigating adaptive batching to intelligently enable batching and adjust batch sizes for best system performance.


