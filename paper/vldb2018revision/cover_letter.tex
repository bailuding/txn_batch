\documentclass{article}

\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{colonequals}
\usepackage[in]{fullpage}
\usepackage{latexsym}
\usepackage{mathrsfs}
\usepackage{subcaption}
%\usepackage{stmaryrd}
\usepackage{indentfirst}
\usepackage{xcolor}

\newcommand{\eat}[1]{}
\newcommand{\eval}[1]{[\![#1]\!]~}
\newcommand{\tuple}[1]{\langle #1 \rangle}
\newcommand{\nil}{\texttt{nil}}
\newcommand{\concat}{\mathrel{\hbox{\scriptsize+}\!\hbox{\scriptsize+}}}

\newcommand{\authorcomment}[2]{{\color{red} !#1: #2}}
\newcommand{\bailu}{\authorcomment{Bailu}}

\long\def\cut#1{{}}

\ifdefined\submit
\newcommand{\todo}[1]{}
\newcommand{\changed}[1]{#1}
\long\def\tocut#1{}
\else
\newcommand{\todo}[1]{\textcolor{red}{\bf [TODO!: #1]}}
\newcommand{\changed}[1]{{\color{blue}#1}}
\newcommand{\tocut}[1]{\textcolor{red}{\it \st{#1}}}
\fi

\begin{document}
\title{Response to Reviews for ``\emph{Improving OCC Performance Through Transaction Batching and Operation Reordering}''}
\author{Bailu Ding, Lucja Kot, Johannes Gehrke}
\date{}
\maketitle

We would like to thank the reviewers and the meta-reviewer for their insightful comments and suggestions. Below is a summary of the changes we made in response to these comments. We have fixed typos and omit such comments in the response. Changes are marked in blue in both the response and the revised submission.

\section{Changes based on meta-reviewer comments}

We first summarize and address the major comments from the reviews.

\begin{itemize}
	\item[(R1)] \emph{Expand the experimental evaluation to include a comparison with other high-performance OLTP engines that use OCC.}
\end{itemize}

\changed{
	\begin{itemize}
		\item We implemented our techniques on top of Cicada and compared with Cicada, Silo, TicToc, and ERMIA. Our techniques improved the best performing OLTP kernel by 2x on write-intensive YCSB benchmark.
		\item The new experiments are in Section 6.7 and Appendix.
	\end{itemize}
}

\begin{itemize}
	\item[(R2)] \emph{Fix typos, unclear parts, and expand discussion per the reviewers requests.}
\end{itemize}

\changed{
	We fixed all the typos mentioned by the reviewers. (TODO)
}

\section{Changes based on individual reviewer comments}

In this section we explain how we addressed individual reviewer comments which are not directly subsumed by a metareviewer comment. We have addressed comments on clarifications of the writing, and omitted similar comments that can be addressed by previous responses.

\subsection{Reviewer 1}

\begin{itemize}
\item[(R1.1)] \emph{Add an experiment to show the performance of the proposed techniques in systems where the clients do not send their next transaction until their previous one is finished.}
\end{itemize}
\changed{
	\begin{itemize}
		\item We integrated our techniques with Cicada to schedule transactions to threads, where each thread processes a transaction synchronously.
		\item We added a new experiment in Section 6.7 and Appendix.
	\end{itemize}
}

\begin{itemize}
\item[(R1.2)] \emph{DBMS-X Add a more detailed description regarding the DBMS-X experiment.}
\end{itemize}

\changed{
	\begin{itemize}
	\item DBMS-X is Hekaton in Microsoft SQL Server. However, we could not disclose the name of the database or its detailed specification. We added a more elaborated description of DBMS-X in Section 6.8 (TODO) \end{itemize}
}

\begin{itemize}
\item[(R1.3)] \emph{Improve the legends of the figures.}
\end{itemize}

\changed{
	We updated the legend to replace unnecessary abbreviations, e.g., bch -> batch.
}

\begin{itemize}
\item[(R1.4)] \emph{Add an experiment to demonstrate to generality of the sort-based algorithm by using more policies or benchmarks.}
\end{itemize}

\changed{
	\begin{itemize}
		\item We agree that the policies should be customized based on the objective of transaction processing system and its architecture.
		\item We extended our sort-based framework to incorporate a thread-aware policy for a multi-threaded synchronous transaction processing OLTP kernel.
		\item We implemented the policy on top of Cicada and our techniques achieved 2x TPS for write-intensive workload.
	\end{itemize}
}

\subsection{Reviewer 2}

\begin{itemize}
\item[(R2.1)] \emph{Add a discussion which explains what constraints on the system make the system best suited for integration with an in-memory versioned key-value store and what would need to change to be integrated with other stores.}
\end{itemize}

\changed{
	\begin{itemize}
		\item Storage is a potential stage of batching and reordering.
		\item If the read and write operations are handled by specific threads in storage, we can batch and reorder the operations to reduce conflicts, as shown in our micro benchmark in Section 6.3.
		\item If the storage is accessed by multi-threads independently, such as in multi-threaded synchronous OLTP kernels, the batching and reordering take place at transaction scheduling time. Our thread-aware reordering policy tends to batch and reorder data accesses to the same object together, which has similar effect as reordering and batching at the storage for operations within the same thread.
	\end{itemize}
}

\begin{itemize}
\item[(R2.2)] \emph{There are many moving parts in the experiments so it is difficult to picture the tradeoffs holistically. I suggest that either the results are represented in a formula or represented in a table showing the tradeoffs.}
\end{itemize}

\changed{
	\begin{itemize}
		\item We added a table to summarize the trade-off of different parameters and policies in Section 6. (TODO)
	\end{itemize}
}

\subsection{Reviewer 3}

\begin{itemize}
\item[(R3.1)] \emph{The papers contains a bag of ideas/optimizations, arguably unrelated,
	based on known techniques, so the overall contributions and novelty is
	limited.}
\end{itemize}

\changed{
	\begin{itemize}
		\item Our contribution is a general framework of batching and reordering for OCC based OLTP systems.
		\item The framework uses a sort-based policy to customize for different transaction processing performance objectives and system architectures.
	\end{itemize}
}

\begin{itemize}
\item[(R3.2)] \emph{Although the evaluation is comprehensive and detailed, but the authors
	only presented a micro benchmark, a self-comparison without considering
	other state-of-the-art approaches. Here are few important related CCs
	(related work discussion can also take into these approaches as well)}
\end{itemize}

\changed{
	\begin{itemize}
		\item We integrated our techniques on top of Cicada and compared our performance of the state of the art OLTP kernels.
		\item The experiments are in Section 6.7 and Appendix.
	\end{itemize}
}

\begin{itemize}
\item[(R3.3)] \emph{The authors provide a black box comparison of their approach in DB-X,
	but the basis of the comparison is unclear (also not sure what does
	"Good Throughput/Transaction" mean). Although the effort is appreciated,
	it would be much better to compare with relevant, disclosed existing
	algorithm, or at the very least, the concurrency of the model of DB-X is
	carefully explained. A black box graph adds no value.}
\end{itemize}

\changed{
	\begin{itemize}
		\item "Good Throughput" means the number of committed transactions per second, since some literature refers "Throughput" as the number of transactions processed per second, regardless either they commit or abort. We explained the term at the end of Section 6.1.
		\item We integrated our techniques to Cicada and added a new experiment to compare our system with other OLTP kernels.
		\item DBMS-X is Hekaton in Microsoft SQL Server. However, we could not disclose the name of the database or its detailed specification. We added a more elaborated description of DBMS-X in Section 6.8 
	\end{itemize}
}


\begin{itemize}
\item[(R3.4)] \emph{It is unclear why the authors choose to have 300 active transactions,
	which would imply the need for having 300 physical threads. I further
	suppose, the authors considering in-memory implementation given all OLTP
	DB can fit entirely in memory today. If in fact, the number of active
	transactions is larger than threads, then there will be many context switches,
	and frankly, the whole setting would be questionable, which could also
	explain why the overall throughput is never exceeded half-million
	transactions/second.}
\end{itemize}

\changed{
	\begin{itemize}
		\item Our micro benchmark is based on a system with asynchronous transaction processing architecture. Each thread multiplexes multiple transactions simultaneously to mask the latency of transaction workflow execution, IO accesses, and network communication. Thus, the number of threads can be much less than the number of transactions. This architecture has loosely coupled components and can scale storage and compute independently, which is especially applicable for elastic transaction processing in the cloud.
		\item We also integrated our techniques to DBMS-X and Cicada, where each thread processes a transaction synchronously and independently. In this case, each thread is pinned to a dedicated physical CPU core and the number of active transactions never exceeds the number of cores. We achieved close to 2 millions transactions per second with write-intensive workload, which is up to 2x compared with the state of the art OLTP kernels.  
		 
	\end{itemize}
}

\begin{itemize}
\item[(R3.5)] \emph{In some graphs, x-axis label is cut off.}
\end{itemize}

\changed{
	We fixed the truncated labels and ticks.
}

\end{document}