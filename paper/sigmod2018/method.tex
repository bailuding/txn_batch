\section{Batching and Reordering}\label{sec:overview}

%In this section, we introduce our novel ideas of batching at the storage and the validator in an OCC system, and we formulate the resulting algorithmic problems. 

\emph{Batching} involves buffering a number of operations as they arrive at some component of the system and processing them as a group. 
Given a batch, we run a lightweight algorithm that analyzes the batch and then reorders the operations in the batch in order to reduce aborts. We will introduce two types of reordering opportunities: Storage batching and validator batching.

We first make a conceptual distinction between two types of transaction aborts: intra-batch and inter-batch aborts. Assume transaction $T$ abort due to its conflict with $T'$. If $T$ and $T'$ are in the same batch, we call the resulting abort of $T'$ an \emph{intra-batch abort}; otherwise, we call it an \emph{inter-batch abort}.
%Batching transactions that access the same objects together reduces inter-batch aborts. 
%There has been a lot of research on data clustering either online or offline~\cite{elmore2015squall, pavlo2012skew}, especially for fine-grained data partitioning. 
In this work, we focus on managing intra-batch aborts by strategically reordering the batched requests at storage and validator. 
Reducing inter-batch aborts is complementary to our effort. 

Our approach is agnostic to isolation levels as long as the reordering respects the corresponding definition of conflicts for 
write-read, write-write, and read-write dependencies. In the remainder of this paper, we describe 
how to batch and reorder for serializability, but our techniques can be adapted accordingly to other isolation levels, 
such as snapshot isolation.

\eat{For example, in snapshot isolation, if the storage is multi-versioned and offers a consistent snapshot to reads, no reordering is needed. At the validator, two transactions in the same batch conflict with each other if they write to the same
object. Thus, we create a dependency graph based on write-write conflicts, and the other parts of the
protocol stay the same. For example, let $T_1$, $T_2$, and $T_3$ be in the same batch, where $T_1$ writes to
$X$, $T_2$ writes to $Y$, and $T_3$ writes to $X$ and $Y$. Committing $T_3$ will lead to the aborts of $T_1$ and $T_2$. But if
we choose to abort $T_3$, $T_1$ and $T_2$ can both commit. }

\subsection{Reordering At The Storage}
If a transaction reads a stale version of an object from the storage layer, it is bound to 
abort at the validator as it conflicts with the update from a committed transaction. 
Thus, applying updates at the storage layer as early as possible can 
reduce the chance of aborts for incoming transactions.

We implement this idea as follows. We buffer a number of read and write requests from transactions into batches. 
As a batch of requests arrives at the storage layer, for each object, we apply the highest-version write request on that object. It is safe to discard all other writes on that object as explained in Section~\ref{sec:background}. Next, we handle all the read requests for the same object. This strategy is optimal for reducing intra-batch aborts, as it ensures that all available writes by committed transactions are applied to all objects before we handle any read requests on these objects. 

\subsection{Validator}\label{subsec:validator_reordering}

In validator batching, we buffer transaction validation requests at the validator as they arrive. Once a batch is collected, the validator can reduce intra-batch aborts by choosing a good validation (and thus resulting serialization) order.
Such intra-batch transaction reordering can be done with several goals in mind. We can simply minimize intra-batch aborts, i.e. we maximize the number of transactions in each batch that commit. Alternatively, we may also want to prioritize certain transactions to have a greater chance of committing. For example, if we want to reduce the transactions' tail latency, we can increase a transaction's priority every time it has to abort and restart. Priorities could also be related to external factors, e.g., a transaction's monetary value or an external, application-defined transaction priority. 
%These choices suggest a range of possible policies; we explore them in the next section.

\subsection{Intra-Batch Validator Reordering (IBVR)}\label{sec:ibvr}
\label{subsec:validator_reordering:algorithm}

We now define the problem of {\em intra-batch validator reordering of transactions (IBVR)} more formally. A \emph{batch} $B$ is a set of transactions to be validated. We assume all transactions $t \in B$ are \emph{viable}, that is, no $t \in B$ conflicts with a committed transaction. If there are non-viable transactions in $B$, they can be removed in preprocessing, as they must always abort.
Given $B$, the goal of IBVR is to find a $B' \subseteq B$ of transactions that must abort due to intra-batch aborts. IBVR must also find a 
%strict (i.e. asymmetric) 
total order $\prec$ on $B \setminus B'$ that \emph{respects all read-write dependencies}; that is, for $t,t'\in B \setminus B'$, if $t \prec t'$, then there is no read-write dependency from $t'$ to $t$.
The validator processes each batch by running IBVR to identify $B'$ and $\prec$, aborting all the transactions in $B'$  and validating the transaction in $B \setminus B'$  in the order $\prec$. By the constraint we gave on $\prec$ above, and from the discussion in Section~\ref{sec:background}, $\prec$ is guaranteed to be a valid serialization order that allows all transactions in $B \setminus B'$  to commit.

%Note that there is always a trivial solution to any IBVR instance: we can choose $B'$ to be all the elements of $B$ except one, so that $B \setminus B'$ has cardinality one. Such solutions are not useful; therefore, every instance of IBVR is associated with an \emph{objective function} on $B'$, and the goal is to find a $B'$ that maximizes the objective function. An example objective function could be the size of $B'$ (smaller is better), or a more complex function that takes into account transaction weights (e.g. priorities).

%Given $B$, the goal of IBVR is to find a $B' \subseteq B$ of transactions that must abort due to intra-batch aborts, and a commit order $Q$ for the remaining transactions that respects all read-write dependencies. The validator processes each batch by running IBVR to identify $B'$ and $Q$, aborting all the transactions in $B'$ and committing remaining transactions in the order of $Q$.

There is always a trivial solution to any IBVR instance: aborting every
transaction but one. Such solutions are not useful; therefore, every instance of
IBVR is associated with an \emph{objective function} on $B'$, and the goal is to
find a $B'$ that maximizes the objective function. A simple objective function
is the size of $B'$ (smaller is better); a more complex one can take into
account transaction priorities, etc. We call the objective function a \emph{policy} $P$.

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\columnwidth]{./alg_fig/fvs-eg}
	\vspace{-1em}
	\caption{An example of a directed graph; node 1 forms a feedback vertex set.}
	\vspace{-1em}
	\label{fig:fvs}
\end{figure}

% dependency graph
%Our algorithms for IBVR are based on a graph representation of the transaction batches. 
Every batch $B$ of viable transactions induces a \emph{dependency graph} $G$; this is a directed graph whose nodes are the transactions in $B$ and whose edges are read-write dependencies.

If $G$ is acyclic, then there exists a commit order $Q$ on $G$ that respects all read-write dependencies. We can construct $Q$ by repeatedly committing a transaction whose corresponding node in $G$ has no outgoing edge using topological sort. If $G$ is not acyclic, we can show that the problem is NP-hard by reducing the NP-hard problem of finding a directed feedback vertex set to it~\cite{karp1972reducibility}. 

A feedback vertex set (FVS) of a directed graph is a subset of vertices whose removal makes the graph acyclic. For example, consider the graph in Figure~\ref{fig:fvs}. The vertex 1 forms a FVS since the graph becomes acyclic after removing vertex 1 and its incoming and outgoing edges. Finding a minimal-size $B'$ for IBVR is exactly the problem of finding the minimal (smallest-size) feedback vertex set on $G$. If we have a more complex objective function for IBVR, we can assign weights to the nodes to represent the desired transaction priorities, and look for a minimum-weight FVS. 
Once we find the FVS $B'$, removing the nodes in $B'$ from $G$ yields an acyclic graph that determines the desired commit order $Q$.

The directed graph FVS (DFVS) problem is well-studied as it has many applications, including deadlock detection, program verification, and Bayesian inference. It is NP-hard and APX-hard~\cite{kann1992approximability, karp1972reducibility}, and it is still an open problem whether there exists any constant-factor approximation.
We propose two greedy algorithms for finding feedback vertex sets -- one based
on the graph's strongly connected components (SCCs) and the other based on sort.
We also introduce a hybrid algorithm that makes strategic use of brute-force search; this is slower but more precise.

\subsection{Greedy Algorithms for IBVR}
All our IBVR algorithms begin by constructing the dependency graph $G$. We start with a set of transactions that have been batched at the validator and construct $B$ by discarding all non-viable transactions. We can identify such transactions by validating each transaction against all the updates prior to this batch.
Next, we create one node per transaction, and one edge per read-write dependency. To determine whether a read-write dependency holds from transaction $t'$ to $t$, we check whether $WS(t) \cap RS(t') \neq \emptyset$. If so, we add an edge from $t'$ to $t$. This can be implemented by creating a hash table from the write sets and probing it with the read sets. Since a write in $t$ can potentially conflict with all the other transactions in the batch, the time complexity to probe the hash table for a single write is $O(|B|)$, where $|B|$ is the size of the batch. The time complexity of building $G$ is $O(|B|^2+|R|+|W|)$, where $|R|$ is the total number of reads, and $|W|$ is the total number of writes. 

We now process $G$ to find a feedback vertex set. Both before and during the
execution of our FVS algorithms, we \emph{trim} the graph to remove all the nodes
that have no incoming edges and/or no outgoing edges; such nodes cannot
participate in any cycles and are thus extraneous for any FVS.

\begin{algorithm}[t]
	\SetAlgoLined\DontPrintSemicolon
	\SetKwProg{main}{Algorithm}{}{}
	\main{GreedySccGraph($G$, $P$)}{
		\KwIn{Directed graph $G$, policy $P$}
		\KwOut{$V$, a feedback vertex set for $G$}
		$V\gets \emptyset$\;
		$G'\gets trim(G)$\;
		$SCC = StronglyConnectedComponents(G')$\;
		\For {$S \in SCC$} {
			$V\gets V\cup GreedyComponent(S, P)$\;
		}
		\Return{$V$}\;
	}{}
	
	\SetKwProg{sub}{Algorithm}{}{}
	\sub{GreedyComponent($S$, $P$)}{
		\KwIn{SCC $S$, policy $P$}
		\KwOut{$V'$, a feedback vertex set for $S$}
		
		\If {$S.size == 1$} {
			\Return{$\emptyset$}\;
		}
		$v\gets SelectVertexByPolicy(S, P)$\;
		$S'\gets GetGraphAfterVertexRemoval(S, v)$\;
		\Return{$v \cup GreedySccGraph(S', P)$}\;
	}{}
	
	\caption{SCC-based greedy algorithm}
	\label{alg:scc}
\end{algorithm}


\begin{algorithm}[t]
	\SetAlgoLined\DontPrintSemicolon
	\SetKwProg{main}{Algorithm}{}{}
	\main{GreedySortGraph($G$, $P$, $k$)}{
		\KwIn{Directed graph $G$, policy $P$, multi factor $k$}
		\KwOut{$V$, a feedback vertex set for $G$}
		$V\gets \emptyset$\;
		$G\gets trim(G)$\;
		\While {$G\neq \emptyset$} {
			\If {$G.size < k$} {
				$V\gets V\cup GreedySortGraph(G, P, 1)$\;
				break\;
			}
			$Q\gets QuickSelectVertexByPolicy(G, P, k)$\;
			\For {$i=1; i\leq k; ++i$} {
				$V\gets V\cup Q[i]$\;
				$G\gets GetGraphAfterVertexRemoval(G, Q[i])$\;
			}
			$G\gets trim(G)$\;
		}
		\Return{$V$}\;
	}{}
	\caption{Sort-based greedy algorithm}
	\label{alg:sort}
\end{algorithm}

{\bf SCC-Based Greedy Algorithm.} The intuition behind our first algorithm is that each cycle must be contained in a strongly connected component of the graph. After preprocessing, we partition the graph into SCCs. For a graph with $V$ vertices and $E$ edges, we can do this in time $O(|V|+|E|)$ using Tarjan's SCC algorithm~\cite{tarjan1972depth}.

Nodes in SCCs of size one cannot belong to any cycle. For a SCC that contains
more than one node, we choose a vertex to remove according to some \emph{policy}. The policy is a ranking function over vertices, and we greedily choose the top-ranked vertex to remove. We then recurse on the remaining graph. Algorithm~\ref{alg:scc} shows the details of this procedure. We begin by trimming and partitioning the graph into SCCs  (lines 3-4). We process each SCC $S$ using $GreedyComponent(S, P)$ (lines 5-7). This subroutine starts by eliminating SCCs of size one (lines 10-12). Next, it chooses the top-ranked vertex $v$ from $S$ under Policy $P$ (line 13). It removes $v$ from $S$ and recursively calls $GreedySccGraph$ on the remaining graph $S'$ (line 14 - 15). Finally, it returns the union of all the FVSs obtained in processing $S$ (line 15). When the top-level procedure $GreedySccGraph(G, P)$ has processed all the SCCs of $G$, it returns the union of the FVSs obtained (line 8).

% Time complexity analysis
$trim$ and updating the graph after removing a node takes $O(|V| + |E|)$ per
graph in total, since each node / edge can be removed only once. In the worst case, e.g., in a fully connected graph, we may only remove one node per iteration. Since SCC takes $O(|V|+|E|)$ per iteration, the time complexity of this algorithm is $O(|V|(|V|+|E|))$.

The policy $P$ is at the heart of the algorithm, and it affects both its accuracy and runtime. Fortunately, there is no trade-off between accuracy and running time; a more accurate policy will lead to a smaller FVS and faster termination. We discuss possible policies in Section \ref{subsec:validator_reordering:policy}.

\begin{figure*}[t]
	\centering
	\begin{minipage}[b]{0.19\linewidth}
		\captionsetup{type=figure}
		\centering
		\subcaptionbox{original\label{fig:scc:g0}}
		{\includegraphics[width=\textwidth]{./alg_fig/scc-g0}}
		%     \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{partition into SCCs\label{fig:scc:g1}}
		{\includegraphics[width=\textwidth]{./alg_fig/scc-g1}}
		%    \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 3 to FVS\label{fig:scc:g3}}
		{\includegraphics[width=\textwidth]{./alg_fig/scc-g3}}
		%       \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 6 to FVS\label{fig:scc:g5}}
		{\includegraphics[width=\textwidth]{./alg_fig/scc-g5}}
		%      \vspace{-2em}
	\end{minipage}                  
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 8 to FVS\label{fig:scc:g7}}
		{\includegraphics[width=\textwidth]{./alg_fig/scc-g7}}
		%     \vspace{-2em}
	\end{minipage}  
	\vspace{-1em}             
	\caption{An example of the SCC-based greedy algorithm using \texttt{prod-degree} policy}
	\vspace{-1em}
	\label{fig:scc}
\end{figure*}

Figure~\ref{fig:scc} shows the SCC-based greedy algorithm. The graph cannot be trimmed, so we partition it into SCCs. We remove all SCCs of size 1 --  Nodes 0, 7, 10, 11, and 12 (Figure~\ref{fig:scc:g1}). There are three remaining SCCs. We first look at the component containing Nodes 3 and 4. Since Nodes 3 and 4 have the same product of in-degree and out-degree, we can add either one of them to the FVS. We choose Node 3. Now Node 4 has neither incoming nor outgoing edges, so it is trimmed (Figure~\ref{fig:scc:g3}). We repeat the process with the other components. For the SCC containing Nodes 2, 5, and 6, we add Node 6 to the FVS, as it has the largest product of in-degree and out-degree among the three nodes in this SCC. We now trim Nodes 2 and 5 (Figure~\ref{fig:scc:g5}). Finally, we remove Node 8 from the last component, and trim Nodes 1 and 9 (Figure~\ref{fig:scc:g7}). This leaves us with a final FVS consisting of Nodes 3, 6, and 8.

{\bf Sort-Based Greedy Algorithm.} Our first algorithm relies on a SCC partitioning routine that takes linear time in the size of the graph. As this routine is called several times throughout the algorithm, it can cause a non-trivial overhead. Here we propose a faster greedy algorithm using a sort-based approach to remove nodes. Through extensive empirical tests of the SCC-based greedy algorithm we found that at each iteration, all the top ranked nodes in the graph are very likely to be included in the final FVS. Our second algorithm is based on this observation; it sorts the nodes according to their policy $P$, and includes the top-ranked $k$ nodes in the FVS. We call $k$ the \emph{multi factor} of the algorithm. The algorithm removes these nodes and iterates on the remaining graph.

Algorithm~\ref{alg:sort} shows this in more detail. We start by trimming the graph (line 3); if the graph has no more than $k$ nodes, we reduce the multi-factor to 1 (line 5-8). Otherwise, we sort and select top ranked $k$ nodes into a queue $Q$ using $P$ with the Quickselect algorithm~\cite{hoare61cacm}, and include the $k$ nodes in $V$ (line 9-13).
After removing the selected nodes from $G$, we trim the remaining the graph
again (line 14). We repeat this procedure until the graph is empty (line 4). 

% time complexity analysis.
As with the previous algorithm, updating the graph after removing a node and \emph{trim} takes $O(|V|+|E|)$ in total. The
Quickselect algorithm~\cite{hoare61cacm} has an amortized time complexity of
$O(|V|)$. In the worst case, it will take $O(|V|/k)$ iterations to terminate. So
the overall time complexity is $O(|V|^2/k + |V| + |E|)$.

In practice, this algorithm is faster but less accurate than the SCC-based greedy algorithm. However, as we will see in Section~\ref{sec:experiments}, it produces results of comparable accuracy to the SCC-based algorithm in practice.

\begin{figure*}[t]
	\centering
	\begin{minipage}[b]{0.19\linewidth}
		\captionsetup{type=figure}
		\centering
		\subcaptionbox{original\label{fig:simple:g0}}
		{\includegraphics[width=\textwidth]{./alg_fig/simple-g0}}
		%     \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 5 to FVS\label{fig:simple:g2}}
		{\includegraphics[width=\textwidth]{./alg_fig/simple-g2}}
		%    \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 8 to FVS\label{fig:simple:g4}}
		{\includegraphics[width=\textwidth]{./alg_fig/simple-g4}}
		%       \vspace{-2em}
	\end{minipage}
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 6 to FVS\label{fig:simple:g6}}
		{\includegraphics[width=\textwidth]{./alg_fig/simple-g6}}
		%      \vspace{-2em}
	\end{minipage}                  
	\begin{minipage}[b]{0.19\linewidth}
		\centering
		\subcaptionbox{add 3 to FVS\label{fig:simple:g8}}
		{\includegraphics[width=\textwidth]{./alg_fig/simple-g8}}
		%     \vspace{-2em}
	\end{minipage}
	\vspace{-1em}             
	\caption{An example of the sort-based greedy algorithm using \texttt{prod-degree} policy and multi factor 1}
	\label{fig:simple}               
	\vspace{-1em}    	
\end{figure*}

Figure~\ref{fig:simple} shows the same example using the sort-based greedy algorithm, with $k = 1$. After the first sort, we add Node 5 to the FVS since it has the highest product of in-degree and out-degree. After eliminating Node 5, Nodes 10 and 12 have only incoming edges, and get trimmed (Figure~\ref{fig:simple:g2}). We sort the remaining nodes. This time, we add Node 8 to the FVS, and trim Nodes 0, 1, 9, 11 (Figure~\ref{fig:simple:g4}). We repeat this process with the remaining nodes until the graph is empty. This yields a FVS consisting of Nodes 3, 5, 6, and 8 (Figure~\ref{fig:simple:g8}), which contains one more vertex than the FVS we obtained with the SCC-based algorithm.

{\bf Hybrid Algorithm.}
%\subsubsection{Hybrid algorithm} 
We can combine the SCC-based greedy algorithm and the precise brute-force FVS search into a \emph{hybrid algorithm}. The algorithm is similar to the SCC-based greedy algorithm but runs a precise, brute-force FVS search whenever it can afford to. Thus instead of processing all SCCs via the $GreedyComponent$ subroutine (lines 5-7 of Algorithm~\ref{alg:scc}), it runs the precise search when processing SCCs that are smaller than a certain \emph{threshold}, and the greedy subroutine $GreedyComponent$ on SCCs that are larger than the threshold. Adjusting the threshold allows us to trade off precision versus runtime.

\subsection{Customizing Policies}
\label{subsec:validator_reordering:policy}
Policies are of utmost importance for our algorithms. Recall that a policy is a ranking function on vertices of the graph, and a good policy ranks vertices which are likely to be in a desirable FVS highly. 

% minimize number of conflicts
We first discuss policies that aim at minimizing the number of conflicts, i.e., the size of the FVS. The simplest such policy is \texttt{random} that assigns all nodes random rankings. Alternatively, we can rank nodes using degree-based heuristics, which use the intuition that the removal of a node will break many cycles if the node is high in some measurement of its graph degree. Such heuristics have  been shown to work well for FVS computation~\cite{cutello2015targeting}. For example, the policy \texttt{max-degree} chooses the node with the largest degree (either in-degree or out-degree), \texttt{sum-degree} chooses the node with the largest total degree (in-degree plus out-degree), and \texttt{prod-degree} chooses the node with the largest product of in-degree and out-degree. 

% minimize tail latency
More sophisticated policies are possible if the system is optimizing a metric beyond maximizing the number of commits. For example, we may want to bound the transactions' \emph{tail latency}; we can do that by incorporating latency information in our policies. We can rank transactions based on how many times they have been aborted and restarted; thus, transactions that have been restarted many times are less likely to enter the FVS and have a higher chance of committing. Alternatively, we can also devise policies that combine information about a transaction's number of restarts and its graph degree. For example, we can compute the ranking of a vertex as the product of its in-degree and out-degree divided by an exponential function of the number of restarts of the corresponding transaction. 

% help with transactions with monetary value
\eat{We can also devise policies that handle hard transactions. In many workloads some transactions are naturally more prone to conflicts, e.g., those that access many objects and/or ``hot'' objects. If we use graph degree based policies, such transactions are likely to be included in the FVS and aborted repeatedly. To avoid starvation, we can adjust our policies to increase the probability that these transactions can commit. For example, we can approximate the ``hardness'' of a transaction by the size of its read and write sets and include that as a weighting factor in the policy.}

In business applications, the monetary value of different transactions varies. Optimizing for \emph{maximal monetary value}, we can design policies that favor more valuable transactions. For example, we can customize the policy to always add a transaction with the lowest value to the FVS until the resulting dependency graph is acyclic.

\subsection{Parallel Reordering and Validation}
\label{subsec:validator_reordering:parallel}
Since reordering occurs online in transaction execution, it can increase the latency of a transaction, resulting in a higher chance of conflicts. We explain how parallelization can alleviate this problem by reducing the amortized overhead of reordering.

In centralized reordering, the validator prepares a batch of transactions, reorders them,  validates them and caches the updates of transactions that commit. Each of these steps corresponds to a subcomponent in the validator; we explain how we can parallelize execution across components through the use of pipelining, as well as within each component. 

% Pipeline parallelism
For pipelined parallelism, we can run each of the three validator subcomponents in a different thread. The batch preparation subcomponent receives requests from the processor, packages transaction into batches, and sends a reordering request to the transaction reordering subcomponent. Next, the transaction reordering subcomponent first pre-validates a batch of transactions based on the latest database snapshot available, then reorders the remaining transactions, and sends a validation request consisting of the remaining transactions to the transaction validation subcomponent. 
The transaction validation subcomponent takes a batch of ordered
transactions, serializes them based on the order, validates them against updates from previously committed transactions, and applies the updates to the validator cache from transactions that pass validation. 

% Compare to single threaded case.
In the single threaded centralized validator, a batch of transactions is
pre-validated against the current snapshot of the database. Thus, the
transactions that pass pre-validation can only conflict with transactions within the batch, and will not conflict with previous committed transactions. So after reordering, the remaining transactions all commit.

In the pipelined reordering, the validation is decoupled into two phases. We denote a database snapshot as $S_k$, where transactions whose timestamps are less or equal to $k$ have been committed as of this snapshot. In the reordering subcomponent, a batch of transactions $B$ is validated against the latest database snapshot $S_m$. The remaining transactions after pre-filtering are reordered as a batch $B'$ and sent to the validation\eat{ subcomponent}. $B'$ is again validated against the current database snapshot $S_n$. Since the validation subcomponent can be validating uncommitted transactions while $B$ is being processed at the reordering subcomponent, when $B'$ arrives at the validation\eat{ subcomponent},  we may have $n\geq m$. Thus, transactions in $B'$ can still abort due to conflicts with previously committed transactions in $S_n$.

% Parallelism in each subcomponent.
We can further introduce parallelism into each of the subcomponents. In batch preparation, multiple threads can package transactions into batches. We can either assign each processor to send its validation request to a specific batch preparation thread, or we can create a consumer-producer queue to connect the processors and the batch preparation threads. In transaction reordering, multiple threads can consume reordering requests from the batch preparation threads, and reorder batches of transactions concurrently. Since the transactions are not serialized yet in the reordering stage, the threads can send the processed batches to the validation subcomponent in any order. At the validation subcomponent, transactions are serialized and validated against all previously committed transactions. We cannot simply validate each individual transaction on a different thread since transactions come from different batches can conflict with each other. However, within an ordered batch, since the only source of conflicts is from all the transactions committed prior the batch, the validation of each transaction within a batch can be processed in parallel. Since conflicts can happen across batch boundaries, processing a new batch should only start after all the transactions are processed in the previous batch. Within a batch, the transactions are serialized by the ordering produced from the reorder subcomponent. The updates from committed transactions in a batch are applied to the validator cache at the end of the processing of the batch. 

% Figure
Figure~\ref{fig:reorder:validator} shows the architecture of our parallel validator. 

\begin{figure}[t]
	\centering
	\includegraphics[width=1\columnwidth]{./figures/validator}
	\vspace{-2em}
	\caption{The architecture of parallel validator. It is decoupled into three subcomponents for pipeline parallelism: batch preparation, transaction reordering, and transaction validation. Each subcomponent can be further parallelized.}
	\vspace{-1em}
	\label{fig:reorder:validator}
\end{figure}

Alternatively, the transaction validation can use partitioned parallelism. The idea is to partition the key space and break a transaction into smaller pieces, and one thread is assigned to validate transaction pieces on one partition. More discussion on this design can be found in our previous Centiman system~\cite{ding2015centiman}.
