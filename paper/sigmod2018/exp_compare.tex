\subsection{Implementation on DBMS-X}
\label{subsec:experiment:compare}

In our final experiment, we implemented the idea of transaction batching and reordering on top of a commercial DBMS-X. DBMS-X is a high performance OLTP engine using optimistic concurrency control. Upon receiving transactions, it processes transactions concurrently with a first-come-first-served order. We implement transaction batching and reordering at the client side of DBMS-X as a proof-of-concept.

In many applications and services, clients submit transactions to databases via a middle-layer, such as a web server. This server consolidates requests from many clients, processes the requests, reroutes the requests to different database servers, and responds to the clients. The web server often batches transactions from different clients to improve throughput and resource efficiency. 

As a prototype, we implemented validator reordering for the transactions batched at the middle-layer -- before submitting the batched transactions to the database server. Since the transactions haven't started executing and their read timestamps are not yet available, we conservatively assume that all the transactions in the batch read from the same snapshot of the database. We analyze the potential conflicts between the transactions, and then we maximize the number of commits of transactions with our reordering algorithm, using a policy considering both how many dependencies a transaction involves and how long it has been waiting. The transactions excluded from the batch, together with future incoming transactions, will be included in the next batch for reordering.

We use SmallBank benchmark of Zipfian skew 0.9 as a highly contended scenario. We compare transaction batching and reordering (\emph{BatchReorder}) with two other baselines: no batching (\emph{NoBatch}) and batch without reordering (\emph{Batch}). In \emph{NoBatch}, we transactions to DBMS-X one at a time. In \emph{Batch} and \emph{BatchReorder}, we batch the transactions before sending the transactions to DBMS-X. We choose a batch size of 50, which is a throughput-wise reasonable batch size for this workload.

Figure~\ref{fig:hekaton:tps}, ~\ref{fig:hekaton:abort}, and ~\ref{fig:hekaton:latency} show the throughput, latency, and abort rate when we increase the number of database connections. When we do not batch the transactions, the number of concurrent transactions is small and the throughput is low. As a result of low concurrency level, the chance of conflicting is small. Thus, both abort rate and latency are low. As we send transactions in batches, the throughput increases dramatically. However, as the load continues to increase, the system runs into data contention, which leads to resource contention due to restarts. The abort rate and latency rise significantly. When we both batch and reorder the transactions, the performance improves in all metrics: peak throughput increased by 1.25x, throughput increased by up to 3.1x, latency decreased by up to 66\%, and abort rate decreased by up to 62\%. In addition, the system performance degrades much more gracefully when the load continues to increase.
