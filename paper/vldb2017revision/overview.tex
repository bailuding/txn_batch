\section{Batching}\label{sec:overview}

%In this section, we introduce our novel ideas of batching at the storage and the validator in an OCC system, and we formulate the resulting algorithmic problems. 

\emph{Batching} involves buffering a number of operations as they arrive at some component of the system and processing them as a group. 
Given a batch, we run a lightweight algorithm that analyzes the batch and then reorders the operations in the batch in order to reduce aborts. We will introduce two types of batching: Validator batching and storage batching.


\subsection{Validator Batching}\label{subsec:overview:validator}

In validator batching, we buffer and batch transaction validation requests at the validator as they arrive.
We can first make a conceptual distinction between two types of transaction aborts: intra-batch and inter-batch aborts. Assume $T(j)$ abort due to its conflict with $T(i)$. If $T(i)$ and $T(j)$ are in the same batch, we call the resulting abort of $T(j)$ an \emph{intra-batch abort}; otherwise, we call it an \emph{inter-batch abort}.
The optimal strategy for reducing inter-batch aborts is to ensure that transactions accessing the same objects are always batched together. That is, to cluster them based on access patterns, since  the validator cannot do anything about conflicting inter-batch transactions. 
There has been a lot of research on data clustering either online or offline~\cite{elmore2015squall, pavlo2012skew}, especially for fine-grained data partitioning. Any of these techniques can be used for validator batch creation.
%However, clustering transactions into batches based on access patterns may increase the number of intra-batch aborts.

Once a batch is collected, the validator can reduce intra-batch aborts by choosing a good validation (and thus resulting serialization) order.
\eat{The validator may not be able to eliminate all intra-batch aborts, since it cannot actually delay the execution of a transaction. Rather, it is presented with read and write sets of transactions that have already run. }
Such intra-batch transaction reordering can be done with several goals in mind. We can simply minimize intra-batch aborts, i.e. we maximize the number of transactions in each batch that commit. However, we may also want to prioritize certain transactions to have a greater chance of committing. For example, if we want to reduce the transactions' tail latency, we can increase a transaction's priority every time it has to abort and restart. Priorities could also be related to external factors, e.g., a transaction's monetary value or an external, application-defined transaction priority. 
%These choices suggest a range of possible policies; we explore them in the next section.

We now define the problem of {\em intra-batch validator reordering of transactions (IBVR)} more formally. A \emph{batch} $B$ is a set of transactions to be validated. We assume all transactions $t \in B$ are \emph{viable}, that is, no $t \in B$ conflicts with a committed transaction. If there are non-viable transactions in $B$, they can be removed in preprocessing, as they must always abort.
Given $B$, the goal of IBVR is to find a $B' \subseteq B$ of transactions that must abort due to intra-batch aborts. IBVR must also find a 
%strict (i.e. asymmetric) 
total order $\prec$ on $B \setminus B'$ that \emph{respects all read-write dependencies}; that is, for $t,t'\in B \setminus B'$, if $t \prec t'$, then there is no read-write dependency from $t'$ to $t$.
The validator processes each batch by running IBVR to identify $B'$ and $\prec$, aborting all the transactions in $B'$  and validating the transaction in $B \setminus B'$  in the order $\prec$. By the constraint we gave on $\prec$ above, and from the discussion in Section~\ref{sec:background}, $\prec$ is guaranteed to be a valid serialization order that allows all transactions in $B \setminus B'$  to commit.

%Note that there is always a trivial solution to any IBVR instance: we can choose $B'$ to be all the elements of $B$ except one, so that $B \setminus B'$ has cardinality one. Such solutions are not useful; therefore, every instance of IBVR is associated with an \emph{objective function} on $B'$, and the goal is to find a $B'$ that maximizes the objective function. An example objective function could be the size of $B'$ (smaller is better), or a more complex function that takes into account transaction weights (e.g. priorities).

%Given $B$, the goal of IBVR is to find a $B' \subseteq B$ of transactions that must abort due to intra-batch aborts, and a commit order $Q$ for the remaining transactions that respects all read-write dependencies. The validator processes each batch by running IBVR to identify $B'$ and $Q$, aborting all the transactions in $B'$ and committing remaining transactions in the order of $Q$.

There is always a trivial solution to any IBVR instance: aborting every transaction but one. Such solutions are not useful; therefore, every instance of IBVR is associated with an \emph{objective function} on $B'$, and the goal is to find a $B'$ that maximizes the objective function. An example objective function could be the size of $B'$ (smaller is better), or a more complex function that takes into account transaction priorities.






\subsection{Storage Batching}
At the storage layer, the optimal batching strategy is simple. We buffer a certain number of read and write requests into batches. The only way to reduce inter-batch aborts is to increase the batch size.\eat{, but we have more flexibility for intra-batch optimizations.} To reduce intra-batch aborts, we propose the following simple algorithm, which is easy to prove to be optimal given a batching:  When a batch is ready (either when there are enough requests or a timeout is reached), for each object we apply the highest-version write request on that object. It is safe to discard all other writes on that object as explained in Section~\ref{sec:background}. Next, we handle all the read requests for the same object. This strategy is optimal for reducing intra-batch aborts, as it ensures that all available writes by committed transactions are applied to all objects before we handle any read requests on these objects. 





\eat{

At the validator, we can change the assignment of timestamps and the resulting serialization order of transactions in order to avoid aborts. The overhead of the reordering impacts transaction latency, so the reordering algorithms must be fast.
For example, we can use operation batching at the storage layer to analyze the sequence of reads and writes and reorder them to avoid some transaction aborts. 


 The type of operations at each component in the system are different. 
 


The goal of batching is to reduce the number of conflicts, 
%by reordering the operations in each batch, 
thus decreasing abort rate, increasing throughput and lowering atency. As explained in Section~\ref{sec:background}, aborts happen due to read-write dependencies involving a committed transaction $T(i)$ that wrote to some object, and a later transaction $T(j)$ that read the same object but did not see $T(i)$'s update. 




In this paper, we propose two types of batching

The server components -- the storage and the validator -- aim to reduce both intra-batch and inter-batch aborts. The storage batches the read and write requests, and the validator batches the validation requests.

Given a batch, the number of intra-batch aborts is determined by the way we order and interleave the requests in processing. Thus the main optimization strategy is \emph{reordering}. 
Neither inter-batch nor intra-batch conflicts can be completely eliminated by reordering. A transaction that passes validation but gets ``stuck'' before writing to the storage will conflict with all subsequent transactions that read the same object, causing unavoidable inter-batch conflicts. Two transactions in the same batch which read and write the same object cannot both commit, thus causing an unavoidable intra-batch conflict.

 %Note that not all components in the system need to batch transactions in the same way.


\eat{
To reduce the number of inter-batch aborts, the system can divide the transactions into batches in a careful manner; it can also privilege writes over reads to allow reads to see fresher values. However, at all times in the system, there are multiple batches in-flight. 

No component can eliminate inter-batch aborts completely and unilaterally. The worst case is a slow transaction that writes an object and passes validation, but whose write gets ``stuck'' in the system and doesn't make it to the storage for a long time. This transaction will conflict with -- and cause inter-batch aborts of -- all subsequent transactions that read the same object, until the write is actually applied.

We now explain the specific batching strategies that are available at the storage and the validator.}
}%\eat