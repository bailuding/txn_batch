\subsection{Storage and Validator Batching}
\label{subsec:experiment:batching}

Next, we perform a detailed analysis on the effects of storage and validator batching. We configure the system in several different modes: no batching ($baseline$), batching only ($batch$), storage batching ($sr$), validator batching only\eat{with the \texttt{prod-degree} policy that maximizes the number of commits }($vc$), and both storage and validator batching ($srvc$).


\eat{As explained in Section~\ref{sec:overview}, batching and reordering affect the abort rate by reducing inter-batch and intra-batch aborts. The number of inter-batch aborts is affected by system-wide transaction latency, the freshness of the transactions' reads, and their access patterns. Validator reordering reduces the number of intra-batch aborts; however, storage reordering can increase the number of such aborts because it reduces inter-batch aborts (and thus more viable transactions end up in validator batches rather than aborting due to inter-batch conflicts). The overall throughput of the system is affected by both the transaction latency and the abort rate. }


Figure~\ref{fig:basic:tps},~\ref{fig:basic:latency}, and~\ref{fig:basic:p95} show the throughput, the average latency, and the percentile latency of different system modes under a variety of data skew parameters. 

Overall, using batching at storage and/or validator consistently leads to significant improvements in the throughput and the latency profiles over the baseline. Batching alone ($batch$) improves the throughput significantly due to lower amortized overhead per transaction and better caching with tighter loops in processing. In addition, storage reordering and validator reordering consistently further improve the throughput. Moreover, validator reordering significantly reduces the average latency and the percentile latencies.

\eat{When batching is enabled ($sr$ and $srvc$), the throughput is 2.1x-2.4x that of the baseline ($baseline$). In addition, using validator batching always gives a better latency profile (Figure~\ref{fig:basic:p95}).}

\eat{When the data contention is very low, the abort rate is low. Thus, the storage-batching-only mode ($sr$) gives similar throughput compared with $srvc$.  As the data skew increases, so does the number of intra-batch conflicts and aborts; the overhead of validator batching starts to pay off. In a medium-contention setting, using both validator and storage batching ($srvc$) gives the best throughput.}
When the data contention is extremely high, the number of intra-batch conflicts
that cannot be resolved by validator reordering increases. Validator reordering
is slower due to denser graphs, while bringing less benefit. Thus, the best throughput is achieved by using storage batching only ($sr$). 

We conducted additional experiments with the batch size fixed to evaluate the system's peak performance with the load varied. Figure~\ref{fig:load_z0.7:tps} shows the throughput of the system with batch size 20 and skew factor 0.7. The throughput increases with the concurrency level of the system, and then degrades as the system is overloaded. Enabling both storage and validator batching consistently outperforms the others. The figures on additional metrics and parameters are omitted due to the space limit.

\eat{
To summarize, it is always beneficial to enable storage batching since this technique reduces inter-batch aborts at a minimal cost. While validator batching consistently gives a percentile latency, it is most effective in mid-contention settings, when the reduction of intra-batch conflicts that it brings is sufficient to justify its cost. }
