\subsection{End-to-End Performance on Benchmarks}
\label{subsec:experiment:end2end}
In our final experiment, we explore the end-to-end performance of batching in a realistic setting where batch size is fixed. We use two workloads: a micro benchmark and the Small Bank benchmark~\cite{alomari2008icde}. In our micro benchmark,  we generate the transactions as described in Section~\ref{subsec:experiment:implementation}. \eat{We introduce skewed accesses to the data where each object is drawn from Zipfian distribution.} The Small Bank benchmark contains transactions with a realistic and diverse combination of read and write conflicts. The transactions come from the financial domain: compute the balance of a customer's checking and savings accounts, deposit money to a checking account, transfer money from a checking account to a savings account, move all funds from one customer to another customer, and withdraw money from a customer's account. We use a Zipfian distribution to simulate skewed data accesses. We populate the database with 100K customers, i.e., 100K checking and 100K savings accounts. We use a batch size of 10 transactions and we vary the system concurrency level from 20 to 140 transactions. We simulate high data contention by introducing Zipfian skew factor (0.7 for the micro benchmark and 0.9 for the Small Bank benchmark, which has shorter transactions).
\eat{, i.e., the limit of active transactions in the system}


\eat{On the micro benchmark, Figure~\ref{fig:load:tps} shows the throughput at skew factor 0.7.} 
On the micro benchmark, Figure~\ref{fig:load:tps} shows the throughput. 
Using batching doubles the throughput as compared to the baseline, both for a given load and when considering the peak throughput over different loads. When the load is moderate, storage batching by itself performs best. As the load increases and the transactions become more conflict-prone, the benefit of validator batching outweighs its cost. This confirms our observation in Section~\ref{subsec:experiment:batching}. 

Figure~\ref{fig:load:latency} shows the average transaction latency. Both storage and validator batching reduce the latency as compared to the baseline. In addition, validator batching always reduces latency regardless of whether storage batching is enabled, again confirming our findings in Section~\ref{subsec:experiment:batching}.

\eat{Figures~\ref{fig:small_bank:tps} and~\ref{fig:small_bank:latency} show the throughput and latency of the system on the Small Bank benchmark at skew factor 0.9. }
Figures~\ref{fig:small_bank:tps} and~\ref{fig:small_bank:latency} show the throughput and latency of the system on the Small Bank benchmark. 
The performance impacts of batching are similar to those on the micro benchmark.
We ran additional experiments on both benchmarks varying the data skew; the results were similar to those shown and are omitted due to space limitations.
