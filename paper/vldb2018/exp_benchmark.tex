\subsection{Small Bank Benchmark}
\label{subsec:experiment:end2end}
\eat{In our final experiment, we explore the end-to-end performance of batching in a realistic setting where batch size is fixed. We use two workloads: a micro benchmark and the Small Bank benchmark~\cite{alomari2008icde}. In our micro benchmark,  we generate the transactions as described in Section~\ref{subsec:experiment:implementation}. \eat{We introduce skewed accesses to the data where each object is drawn from Zipfian distribution.} }

\eat{In this experiment, we explore the end-to-end performance of batching in a realistic setting. We choose the same Small Bank benchmark as in Section~\ref{subsec:experiment:compare}.}

The Small Bank benchmark~\cite{alomari2008icde} contains transactions with a realistic and diverse
combination of read and write conflicts. The transactions come from the
financial domain: compute the balance of a customer's checking and savings
accounts, deposit money to a checking account, transfer money from a checking
account to a savings account, move funds from one customer to another, and withdraw money from a customer's account. We use a Zipfian distribution to simulate skewed data accesses. We populate the database with 100K customers, i.e., 100K checking and 100K savings accounts.

Figure~\ref{fig:small_bank:tps},~\ref{fig:small_bank:latency},~\ref{fig:small_bank:p95} show the throughput, the average latency, and the percentile latency of transactions. Overall, batching and reordering improved the throughput by up to 3.1x, reduced average latency by up to 68\%, and tail latency by up to 62\%. Storage and validator reordering can always improve the throughput and reduce the latency on top of batching, confirming our findings in Section~\ref{subsec:experiment:batching}.

\eat{On the micro benchmark, Figure~\ref{fig:load_z0.7:tps} shows the throughput with skew factor 0.7. Overall, batching has improved the throughput 
Using batching doubles the throughput as compared to the baseline, both for a given load and when considering the peak throughput over different loads. When the load is moderate, storage batching by itself performs best. As the load increases and the transactions become more conflict-prone, the benefit of validator batching outweighs its cost. }

\eat{Figure~\ref{fig:load_z0.7:latency} shows the average transaction latency with skew factor 0.7. Both storage and validator batching reduce the latency as compared to the baseline. Validator batching gives the lowest latency when the data is extremely skewed. In addition, validator batching always reduces latency regardless of whether storage batching is enabled, again confirming our findings in Section~\ref{subsec:experiment:batching}. The performance impacts of batching are similar to those on the micro benchmark. 

The experiments with additional parameters show similar performance impact with batching. We omit the figures due to the space limit.}%eat
