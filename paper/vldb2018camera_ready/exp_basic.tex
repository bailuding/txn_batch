\subsection{Storage and Validator Batching}
\label{subsec:experiment:batching}

Next, we perform a detailed analysis on the effects of storage and validator batching. We configure the system in several different modes: no batching ($base$), batching without reordering (\changed{$batch$}), storage only batching with reordering ($sr$), validator only batching with reordering
%\eat{with the \texttt{prod-degree} policy that maximizes the number of commits }
($vc$), and both storage and validator batching with reordering ($srvc$).


\eat{As explained in Section~\ref{sec:overview}, batching and reordering affect the abort rate by reducing inter-batch and intra-batch aborts. The number of inter-batch aborts is affected by system-wide transaction latency, the freshness of the transactions' reads, and their access patterns. Validator reordering reduces the number of intra-batch aborts; however, storage reordering can increase the number of such aborts because it reduces inter-batch aborts (and thus more viable transactions end up in validator batches rather than aborting due to inter-batch conflicts). The overall throughput of the system is affected by both the transaction latency and the abort rate. }%end of \eat


Figures~\ref{fig:basic:tps},~\ref{fig:basic:latency}, and~\ref{fig:basic:p95} show the throughput, the average and percentile latency of different system modes under various data skews. Using batching with reordering at the storage and/or validator consistently improves throughput by up to 2.7x. In addition, reordering ($sr$) on top of batching (\changed{$batch$}) consistently improves the throughput to up to $1.3\times$. Moreover, validator reordering significantly reduces the average and tail latency by up to $67\%$ and $82\%$ respectively, compared with the baseline ($base$).\cut{, and by up to 25\% and 70\% as compared to \changed{$batch$}.}

%\eat{When batching is enabled ($sr$ and $srvc$), the throughput is 2.1x-2.4x that of the baseline ($baseline$). In addition, using validator batching always gives a better latency profile (Figure~\ref{fig:basic:p95}).}
%\eat{When the data contention is very low, the abort rate is low. Thus, the storage-batching-only mode ($sr$) gives similar throughput compared with $srvc$.  As the data skew increases, so does the number of intra-batch conflicts and aborts; the overhead of validator batching starts to pay off. In a medium-contention setting, using both validator and storage batching ($srvc$) gives the best throughput.}
When the data contention is extremely high (i.e., skew factor 0.9), the number of intra-batch conflicts
that cannot be resolved by validator reordering increases. Validator reordering
is slower due to denser graphs, while bringing less benefit. Thus, the best throughput in this case is achieved by using storage only batching with reordering ($sr$). 

\eat{We conducted additional experiments to evaluate the performance with a fixed workload and varying load. Figure~\ref{fig:load_z0.7:tps} shows the throughput of the system with skew factor 0.7. The configuration that enables both storage and validator batching with reordering consistently outperforms the others. The throughput increases by up to 2.5x, and the average latency is reduced by up to 63\% as compared to $base$. More figures on additional metrics and parameters are omitted due space limits.}

\eat{
To summarize, it is always beneficial to enable storage batching since this technique reduces inter-batch aborts at a minimal cost. While validator batching consistently gives a percentile latency, it is most effective in mid-contention settings, when the reduction of intra-batch conflicts that it brings is sufficient to justify its cost. }

We further evaluate batching and reordering on the Small Bank Benchmark~\cite{alomari2008icde}. The Small Bank benchmark contains transactions with a realistic and diverse
combination of read and write conflicts: compute the balance of a customer's checking and savings
accounts, deposit money to a checking account, transfer money from a checking
account to a savings account, move funds from one customer to another, and withdraw money from a customer's account. We use a Zipfian distribution to simulate skewed data accesses. We populate the database with 100K customers, including 100K checking and 100K savings accounts.

Figure~\ref{fig:small_bank:tps},~\ref{fig:small_bank:latency},~\ref{fig:small_bank:p95} show the throughput, the average and percentile latency of transactions.\cut{ Overall, batching and reordering improved the throughput by up to $3.1\times$, reduced average latency by up to $68\%$, and tail latency by up to $62\%$.} The benefits of batching and reordering are similar to these on our micro benchmark.\cut{, storage and validator reordering can always improve the throughput and reduce the latency on top of batching. confirming our findings in Section~\ref{subsec:experiment:batching}.}

