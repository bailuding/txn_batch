\begin{abstract}
	OLTP systems can often improve throughput by \emph{batching} transactions and processing them as a group. Batching has been used for optimizations such as message packing and group commits; however, there is little research on the benefits of a holistic approach to batching across a transaction's entire life cycle.
	
In this paper, \changed{we present a framework to incorporate batching at multiple stages of transaction execution for OLTP systems based on optimistic concurrency control. }
%Execution batching enables enables reordering of operations to improve performance and reduce conflicts: 
Storage batching enables reordering of transaction reads and writes at the storage layer, reducing \changed{conflicts on the same object}. Validator batching enables reordering of transactions before validation, reducing conflicts between transactions. Dependencies between transactions make transaction reordering a non-trivial problem, and we propose several efficient and practical algorithms that can be customized to various transaction precedence policies such as reducing tail latency. \changed{We also show how to reorder transactions with a thread-aware policy in multi-threaded OLTP architecture without a centralized validator.
	\cut{We also show how to parallelize validator batching for better performance}
	
	
In-depth experiments on a research prototype, an open-source OLTP system, and a production OLTP system show that our techniques increase transaction throughput by up to 2.2x and reduce their tail latency by up to 71\% compared with the start-of-the-art systems on workloads with high data contention.
} 
\end{abstract}